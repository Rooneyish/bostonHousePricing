


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline





from sklearn.datasets import 


boston = pd.read_csv('BostonHousing.csv')


data.keys()





california


print(california.target)


print(california.feature_names)











df = pd.DataFrame(california.data, columns= california.feature_names)


df.head()





df['Price'] = california.target


df


df.info()





df.describe()





df.isnull()


df.isnull().sum()








corr= df.corr()


corr


sns.heatmap(corr, cmap="Blues")
plt.show()











sns.regplot(x="MedInc", y="Price", data=df, line_kws={"color": "red"})
plt.show()





sns.regplot(x="AveRooms", y="AveBedrms", data=df, line_kws={"color": "red"})
plt.show()





sns.regplot(x="MedInc", y="AveRooms", data=df, line_kws={"color": "red"})
plt.show()


sns.regplot(x="Population", y="HouseAge", data=df, line_kws={"color": "red"})
plt.show()


sns.regplot(x="Population", y="MedInc", data=df, line_kws={"color": "red"})
plt.show()





X = df.iloc[:,:-1] # independent features
y = df.iloc[:, -1] # dependent features


print(y.head())


X.head()





from sklearn.model_selection import train_test_split


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


X_train


X_test


y_train


y_test





from sklearn.preprocessing import StandardScaler


scaler = StandardScaler()


X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


X_train_scaled


X_test_scaled





from sklearn.linear_model import LinearRegression


regression = LinearRegression()


regression.fit(X_train, y_train)


## print the coefficents (w_n values) and the intercept (b value)
print(f'w vector: {regression.coef_}') 
print(f'b value: {regression.intercept_}')


## on which parameters the model has been trained
regression.get_params() 


### Prediction With Test Data
reg_predict = regression.predict(X_test)
reg_predict


### Plot a scatter plot for the prediction
plt.scatter(reg_predict, y_test)
plt.xlabel('predictions')
plt.ylabel('test data')
plt.show()


## Residuals
residuals = y_test - reg_predict
residuals


## Plot the residuals
sns.displot(residuals, kind = 'kde')
plt.show()


## Scatter plot with respect to prediction and residuals
plt.scatter(reg_predict, residuals)
plt.xlabel('prediction')
plt.ylabel('residuals')
plt.show()


from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

print(mean_absolute_error(y_test, reg_predict))
print(mean_squared_error(y_test, reg_predict))
print(np.sqrt(mean_squared_error(y_test, reg_predict)))


### R square and adjusted R square
